<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Infrastructure-mgmt | Quick Notes]]></title>
  <link href="http://asquareb.github.io/blog/categories/infrastructure-mgmt/atom.xml" rel="self"/>
  <link href="http://asquareb.github.io/"/>
  <updated>2022-01-23T22:06:44-08:00</updated>
  <id>http://asquareb.github.io/</id>
  <author>
    <name><![CDATA[asquareb]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Integrating Chef and Apache ZooKeeper for Coordination in a Cluster]]></title>
    <link href="http://asquareb.github.io/blog/2015/04/03/integrating-chef-and-apache-zookeeper-for-coordination-in-a-cluster/"/>
    <updated>2015-04-03T23:36:21-04:00</updated>
    <id>http://asquareb.github.io/blog/2015/04/03/integrating-chef-and-apache-zookeeper-for-coordination-in-a-cluster</id>
    <content type="html"><![CDATA[<p>In a cluster environment services on nodes may have to be coordinated for various reasons. For e.g., when a configuration change is made to a distributed computing component like <code>HDFS</code>, the <code>HDFS</code> service on all nodes shouldn&rsquo;t stop at the same time to restart so that the configuration takes in effect. Stopping of the service on all the nodes will end up in unavailability which is not desired to put it lightly.</p>

<p>There are many options to perform orchestration/coordination with varied maturity when you manage a cluster using <code>Chef</code>. Here we look at how <code>Chef</code> and <code>ZooKeeper</code> can work together to perform coordination of services on cluster nodes. We will use the need to control and coordinate service restart so that the service in all nodes are not stopped at the same time as the example to explain the solution.</p>

<!--more-->


<p>Lets take the simple case of service restart where only one instance of the service can be restarted at any time. One of the ways to accomplish this is by forcing nodes to acquire a lock to perform service restarts. The following is the solution summary</p>

<ul>
<li>A lock need to be acquired by a node before it can take a restart action on the service instance running on the node.</li>
<li>When a node tries to acquire a lock and if it fails since some other node is holding the lock or other reasons, the node waits and retries for a certain time.</li>
<li>If the lock is acquired within the certain prescribed time, the node restarts the service.</li>
<li>Once the restart is complete the node releases the lock so that other nodes can take a lock on it.</li>
<li>If the lock is not acquired within the certain time, the node remembers that the restart was not successful and hence will try to restart the service next time chef client runs on the node.</li>
</ul>


<p>If there are any misconfigurations which triggered the restart, the service will not be successfully restarted due to the misconfiguration on the node which acquired the lock first. Since the restart process failed, lock will not be released resulting in other nodes not being able to able to acquire it. This prevents misconfiguration being propagated to other nodes preventing unavailability. Also until the misconfiguration is corrected the service will not be restarted in all the nodes.</p>

<p>Now the key is to be able to implement lock primitive in a distributed environment and this is where <a href="https://zookeeper.apache.org/">Apache ZooKeeper</a> comes into play. <code>ZooKeeper</code> is a high-performance coordination service which among many things provides synchronization for distributed applications. <code>ZooKeeper</code> is used by many Apache projects like <code>HBase</code> which is a distributed scalable data store. <code>ZooKeeper</code> is also a distributed system which means failover is handled automatically preventing unavailability.</p>

<p>For the use case of allowing only one node to restart a service, we can use ZooKeeper “znode” as the lock. For a service “X”, if a node is able to create a znode “X” in ZooKeeper then the service can be restarted by the node. If a node is not able to create znode “X” since the znode is already created by another node in the cluster or other reasons, then the node need to wait until the znode is removed.</p>

<p>The following is a Chef <a href="https://github.com/bijugs/chef-bach/blob/master_rolling_restart/cookbooks/bcpc-hadoop/definitions/hadoop_service.rb"><code>definition</code></a> which implements the restart coordination logic. It is implemented as a <code>definition</code> so that it can be used to coordinate the restart of multiple services in a cluster. The inline comments in the code explains the logic and any reference to hadoop can be discarded since this can be used for any service. Currently this is implemented and used for a hadoop cluster.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;h1>Definition takes three parameters&lt;/h1>
</span><span class='line'>
</span><span class='line'>&lt;h1>service_name: Name of the service&lt;/h1>
</span><span class='line'>
</span><span class='line'>&lt;h1>dependencies: Resources typically template resources for which the service need to be restarted&lt;/h1>
</span><span class='line'>
</span><span class='line'>&lt;h1>process_identifier: String which identifies the process of the service&lt;/h1>
</span><span class='line'>
</span><span class='line'>&lt;p>#
</span><span class='line'>define :hadoop_service, :service_name => nil, :dependencies => nil, :process_identifier => nil do&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;p>  params[:service_name] ||= params[:name]
</span><span class='line'>  #
</span><span class='line'>  # Service resource defined using the parameters passed
</span><span class='line'>  #
</span><span class='line'>  service &ldquo;#{params[:service_name]}&rdquo; do
</span><span class='line'>    supports :status => true, :restart => true, :reload => false
</span><span class='line'>    action [:enable, :start]
</span><span class='line'>  end
</span><span class='line'>  #
</span><span class='line'>  # Checking to see whether user requested to not to use restart coordination
</span><span class='line'>  #
</span><span class='line'>  if node[&ldquo;bcpc&rdquo;][&ldquo;hadoop&rdquo;][&ldquo;skip_restart_coordination&rdquo;]
</span><span class='line'>    Chef::Log.info &ldquo;Coordination of #{params[:service_name]} restart will be skipped as per user request.&rdquo;
</span><span class='line'>    begin
</span><span class='line'>      res = resources(service: &ldquo;#{params[:service_name]}&rdquo;)
</span><span class='line'>      if params[:dependencies]
</span><span class='line'>        params[:dependencies].each do |dep|
</span><span class='line'>          res.subscribes(:restart, &ldquo;#{dep}&rdquo;, :delayed)
</span><span class='line'>        end
</span><span class='line'>      end
</span><span class='line'>    rescue Chef::Exceptions::ResourceNotFound
</span><span class='line'>      Chef::Log.info(&ldquo;Resource service #{params[:service_name]} not found&rdquo;)
</span><span class='line'>    end
</span><span class='line'>  else
</span><span class='line'>    if !params[:process_identifier]
</span><span class='line'>      Chef::Application.fatal!(&ldquo;hadoop_service for #{params[:service_name]} need to specify a valid value for the parameter :process_identifier&rdquo;)
</span><span class='line'>    end
</span><span class='line'>    #
</span><span class='line'>    # When there is a need to restart a hadoop service, a lock need to be taken so that the restart is sequenced preventing all nodes being down at the sametime
</span><span class='line'>    # If there is a failure in acquiring a lock with in a certian period, the restart is scheduled for the next run on chef-client on the node.
</span><span class='line'>    # To determine whether the prev restart failed is the node attribute node[:bcpc][:hadoop][:service_name][:restart_failed] is set to true
</span><span class='line'>    # This ruby block is to check whether this node attribute is set to true and if it is set then gets the hadoop service restart process in motion.
</span><span class='line'>    #
</span><span class='line'>    ruby_block &ldquo;handle_prev&lt;em>#{params[:service_name].gsub(&lsquo;-&rsquo;,&lsquo;&lt;/em>&rsquo;)}&lt;em>restart_failure&rdquo; do
</span><span class='line'>      block do
</span><span class='line'>        Chef::Log.info &ldquo;Need to restart #{params[:service_name]} since it failed during the previous run. Another node&rsquo;s restart process failure is a possible reason&rdquo;
</span><span class='line'>      end
</span><span class='line'>      action :create
</span><span class='line'>      only_if { node[:bcpc][:hadoop][params[:service_name].gsub(&lsquo;-&rsquo;,&lsquo;&lt;/em>&rsquo;).to_sym][:restart_failed] and
</span><span class='line'>              !process_restarted_after_failure?(node[:bcpc][:hadoop][params[:service_name].gsub(&lsquo;-&rsquo;,&lsquo;&lt;em>&rsquo;).to_sym][:restart_failed_time],&ldquo;#{params[:process_identifier]}&rdquo;)}
</span><span class='line'>    end
</span><span class='line'>    #
</span><span class='line'>    # Since string with all the zookeeper nodes is used multiple times this variable is populated once and reused reducing calls to Chef server
</span><span class='line'>    #
</span><span class='line'>    zk_hosts = (get_node_attributes(MGMT_IP_ATTR_SRCH_KEYS,&ldquo;zookeeper_server&rdquo;,&ldquo;bcpc-hadoop&rdquo;).map{|zkhost| &ldquo;#{zkhost[&lsquo;mgmt_ip&rsquo;]}:#{node[:bcpc][:hadoop][:zookeeper][:port]}&rdquo;}).join(&ldquo;,&rdquo;)
</span><span class='line'>    #
</span><span class='line'>    # znode is used as the locking mechnism to control restart of services. The following code is to build the path
</span><span class='line'>    # to create the znode before initiating the restart of hadoop service
</span><span class='line'>    #
</span><span class='line'>    lock_znode_path = format_restart_lock_path(node[:bcpc][:hadoop][:restart_lock][:root],&ldquo;#{params[:service_name]}&rdquo;)
</span><span class='line'>    #
</span><span class='line'>    # All hadoop service restart situations like changes in config files or restart due to previous failures invokes this ruby_block
</span><span class='line'>    # This ruby block tries to acquire a lock and if not able to acquire the lock, sets the restart_failed node attribute to true
</span><span class='line'>    #
</span><span class='line'>    ruby_block &ldquo;acquire_lock_to_restart&lt;/em>#{params[:service_name].gsub(&lsquo;-&rsquo;,&lsquo;&lt;em>&rsquo;)}&rdquo; do
</span><span class='line'>      require &lsquo;time&rsquo;
</span><span class='line'>      block do
</span><span class='line'>        tries = 0
</span><span class='line'>        Chef::Log.info(&ldquo;#{node[:hostname]}: Acquring lock at #{lock_znode_path}&rdquo;)
</span><span class='line'>        while true
</span><span class='line'>          lock = acquire_restart_lock(lock_znode_path, zk_hosts, node[:fqdn])
</span><span class='line'>          if lock
</span><span class='line'>            break
</span><span class='line'>          else
</span><span class='line'>            tries += 1
</span><span class='line'>            if tries >= node[:bcpc][:hadoop][:restart_lock_acquire][:max_tries]
</span><span class='line'>              failure_time = Time.now().to_s
</span><span class='line'>              Chef::Log.info(&ldquo;Couldn&rsquo;t acquire lock to restart &rdquo;)
</span><span class='line'>              node.set[:bcpc][:hadoop][params[:service_name].gsub(&lsquo;-&rsquo;,&lsquo;&lt;/em>&rsquo;).to_sym][:restart_failed] = true
</span><span class='line'>              node.set[:bcpc][:hadoop][params[:service_name].gsub(&lsquo;-&rsquo;,&lsquo;&lt;em>&rsquo;).to_sym][:restart_failed_time] = failure_time
</span><span class='line'>              node.save
</span><span class='line'>              break
</span><span class='line'>            end
</span><span class='line'>            sleep(node[:bcpc][:hadoop][:restart_lock_acquire][:sleep_time])
</span><span class='line'>          end
</span><span class='line'>        end
</span><span class='line'>      end
</span><span class='line'>      action :nothing
</span><span class='line'>      if params[:dependencies]
</span><span class='line'>        params[:dependencies].each do |dep|
</span><span class='line'>          subscribes :create, &ldquo;#{dep}&rdquo;, :immediate
</span><span class='line'>        end
</span><span class='line'>      end
</span><span class='line'>      subscribes :create, &ldquo;ruby_block[handle_prev&lt;/em>#{params[:service_name].gsub(&lsquo;-&rsquo;,&lsquo;&lt;em>&rsquo;)}&lt;/em>restart_failure]&rdquo;, :immediate
</span><span class='line'>    end
</span><span class='line'>    #
</span><span class='line'>    # If lock is acquired by the node, ruby_block executes which is to notify service to restart
</span><span class='line'>    #
</span><span class='line'>    ruby_block &ldquo;coordinate&lt;em>#{params[:service_name].gsub(&lsquo;-&rsquo;,&lsquo;&lt;/em>&rsquo;)}_restart&rdquo; do
</span><span class='line'>      block do
</span><span class='line'>        Chef::Log.info(&ldquo;Data node will be restarted in node #{node[:fqdn]}&rdquo;)
</span><span class='line'>      end
</span><span class='line'>      action :create
</span><span class='line'>      only_if { my_restart_lock?(lock_znode_path, zk_hosts, node[:fqdn]) }
</span><span class='line'>    end&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;pre>&lt;code>begin
</span><span class='line'>  res = resources(service: "#{params[:service_name]}")
</span><span class='line'>  res.subscribes(:restart, "ruby_block[coordinate_#{params[:service_name].gsub('-','_')}_restart]", :immediate)
</span><span class='line'>rescue Chef::Exceptions::ResourceNotFound
</span><span class='line'>  Chef::Log.info("Resource service #{params[:service_name]} not found")
</span><span class='line'>end
</span><span class='line'>#
</span><span class='line'># Once the service restart is complete, the following block releases the lock 
</span><span class='line'>#
</span><span class='line'>ruby_block "release_#{params[:service_name].gsub('-','_')}_restart_lock" do
</span><span class='line'>  block do
</span><span class='line'>    Chef::Log.info("#{node[:hostname]}: Releasing lock at #{lock_znode_path}")
</span><span class='line'>    lock_rel = rel_restart_lock(lock_znode_path, zk_hosts, node[:fqdn])
</span><span class='line'>    if lock_rel
</span><span class='line'>      node.set[:bcpc][:hadoop][params[:service_name].gsub('-','_').to_sym][:restart_failed] = false
</span><span class='line'>      node.save
</span><span class='line'>    end
</span><span class='line'>  end
</span><span class='line'>  action :create
</span><span class='line'>  only_if { my_restart_lock?(lock_znode_path, zk_hosts, node[:fqdn]) }
</span><span class='line'>end
</span><span class='line'>&lt;/code>&lt;/pre>
</span><span class='line'>
</span><span class='line'>&lt;p>  end&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;p></span></code></pre></td></tr></table></div></figure></p>

<p>The following code snippet is how it is used in recipes instead of the default Chef <code>service</code> resource.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&hellip;
</span><span class='line'>dep = [&ldquo;template[/etc/hadoop/conf/hdfs-site.xml]&rdquo;,
</span><span class='line'>       &ldquo;template[/etc/hadoop/conf/hadoop-env.sh]&rdquo;]&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;p>hadoop_service &ldquo;hadoop-hdfs-datanode&rdquo; do
</span><span class='line'>  dependencies dep
</span><span class='line'>  process_identifier &ldquo;org.apache.hadoop.hdfs.server.datanode.DataNode&rdquo;
</span><span class='line'>end</span></code></pre></td></tr></table></div></figure></p>

<p>Given this framework it is easier to implement complex logic to determine restart eligibility like rack awareness, restart greater than one node or a set percentage of nodes, restart based on the state of other services in the cluster etc. Also this can be used to implement rolling upgrades of software on cluster nodes. In short there are many options and use cases which can leverage this solution.</p>

<p>Quick word on handling failure during lock acquisition. When the node tries to acquire the lock and fails, the whole chef-client run process could have been stopped or waited for the lock to become available. Both of the options are not desirable as one could understand the implications. That being the reason for choosing the approach of waiting for sometime for the lock to become available and if not remember that the restart need to happen in the next chef-client run. This has the advantage of chef-client run further steps and be successful even when the particular service is not restarted and also automatically restart the service in the next chef-client run which seems like a balanced approach.</p>

<p>Note this solution uses the <code>zookeeper</code> ruby gem and the complete code can be found in the <a href="https://github.com/bloomberg/chef-bach/tree/master/cookbooks/bcpc-hadoop">chef-bach bcpc-hadoop cookbook</a>.</p>

<p>More notes on this category can be found <a href="http://blog.asquareb.com/blog/categories/chef/">here</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Restart of a Service Which Is Dependent on Multiple Services Through Chef]]></title>
    <link href="http://asquareb.github.io/blog/2015/02/28/restart-of-a-service-which-is-dependent-on-multiple-services-through-chef/"/>
    <updated>2015-02-28T23:07:47-04:00</updated>
    <id>http://asquareb.github.io/blog/2015/02/28/restart-of-a-service-which-is-dependent-on-multiple-services-through-chef</id>
    <content type="html"><![CDATA[<p>In a node there can be services that are dependent on other services. For e.g. a monitoring service is dependent on services which it monitors and collects data. So when a service being monitored is restarted, the service monitoring may have to be restarted to establish back the connections. This was the case with older version of JMXTrans which required a restart when any of the services it is monitoring got restarted. Assuming that the older version of JMXTrans is used to monitor various services running on a node how do we restart JMXTrans when any of the process is restarted while using <code>Chef</code> to manage the environment.</p>

<!--more-->


<p>First, the processes which need to be monitored can vary in each node and there can be one or many processes. Since Chef role determines the recipes which are run on a node, a default attribute can be added to define the services JMXTrans is dependent on. The following is an example</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&hellip;
</span><span class='line'>&ldquo;default_attributes&rdquo; : {
</span><span class='line'>   &ldquo;jmxtrans&rdquo;:{
</span><span class='line'>      &ldquo;servers&rdquo;:[
</span><span class='line'>                  {
</span><span class='line'>                    &ldquo;type&rdquo;: &ldquo;datanode&rdquo;,
</span><span class='line'>                    &ldquo;service&rdquo;: &ldquo;hadoop-hdfs-datanode&rdquo;,
</span><span class='line'>                    &ldquo;service_cmd&rdquo;: &ldquo;org.apache.hadoop.hdfs.server.datanode.DataNode&rdquo;
</span><span class='line'>                  },
</span><span class='line'>                  {
</span><span class='line'>                    &ldquo;type&rdquo;: &ldquo;hbase_rs&rdquo;,
</span><span class='line'>                    &ldquo;service&rdquo;: &ldquo;hbase-regionserver&rdquo;,
</span><span class='line'>                    &ldquo;service_cmd&rdquo;: “org.apache.hadoop.hbase.regionserver.HRegionServer"
</span><span class='line'>                  }
</span><span class='line'>                ]
</span><span class='line'>              } &hellip;</span></code></pre></td></tr></table></div></figure></p>

<p>Here the <code>service</code> key defines the name of the service on which JMXTrans is dependent on. The <code>service_cmd</code> key stores a string which can uniquely identify the running process of the service. The <code>type</code> key is not relevant for this discussion. These attributes will change for each role based on which service is installed as part of the role.</p>

<p>Since JMXTRans need to be installed, configured and started on all the nodes to collect statistics from various services a recipe need to be created for the same. But the recipe can now take into account the new node attribute to build the JMXTrans restart logic. The following is a sample code snippet which shows how the logic can be built</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&hellip;
</span><span class='line'>jmx_services = Array.new&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;p>node[&lsquo;jmxtrans&rsquo;][&lsquo;servers&rsquo;].each do |server|
</span><span class='line'>  jmx_services.push(server[&lsquo;service&rsquo;])
</span><span class='line'>  jmx_srvc_cmds[server[&lsquo;service&rsquo;]] = server[&lsquo;service_cmd&rsquo;]
</span><span class='line'>end&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;p>service &ldquo;restart jmxtrans on dependent service&rdquo; do
</span><span class='line'>  service_name &ldquo;jmxtrans&rdquo;
</span><span class='line'>  supports :restart => true, :status => true, :reload => true
</span><span class='line'>  action   :restart
</span><span class='line'>  #
</span><span class='line'>  # Create subcribes entries for each of the services on which JMXTrans is dependent on
</span><span class='line'>  #
</span><span class='line'>  jmx_services.each do |jmx_dep_service|
</span><span class='line'>    subscribes :restart, &ldquo;service[#{jmx_dep_service}]&rdquo;, :delayed
</span><span class='line'>  end
</span><span class='line'>end
</span><span class='line'>&hellip;</span></code></pre></td></tr></table></div></figure></p>

<p>With the <code>subscribes</code> clause added to the <code>service</code> resource for every service JMXTrans is monitoring on the node, restarts of any of these services during <code>chef-client</code> run will make sure that JMXTrans service is restarted.</p>

<p>But what will happen if any of the dependent service is restarted externally for e.g. manually or upstart bounces a service. Then Chef will not restart JMXTrans during <code>chef-client</code> run since all the services are running. This will result in services restarted manually not being monitored by JMXTrans. The following is an updated code snippet which will handle this scenario. The complete recipe is available <a href="https://github.com/bloomberg/chef-bach/blob/master/cookbooks/bcpc_jmxtrans/recipes/default.rb">here</a>.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&hellip;
</span><span class='line'>jmx_services = Array.new
</span><span class='line'>jmx_srvc_cmds = Hash.new
</span><span class='line'>node[&lsquo;jmxtrans&rsquo;][&lsquo;servers&rsquo;].each do |server|
</span><span class='line'>  jmx_services.push(server[&lsquo;service&rsquo;])
</span><span class='line'>  jmx_srvc_cmds[server[&lsquo;service&rsquo;]] = server[&lsquo;service_cmd&rsquo;]
</span><span class='line'>end&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;p>service &ldquo;restart jmxtrans on dependent service&rdquo; do
</span><span class='line'>  service_name &ldquo;jmxtrans&rdquo;
</span><span class='line'>  supports :restart => true, :status => true, :reload => true
</span><span class='line'>  action   :restart
</span><span class='line'>  jmx_services.each do |jmx_dep_service|
</span><span class='line'>    subscribes :restart, &ldquo;service[#{jmx_dep_service}]&rdquo;, :delayed
</span><span class='line'>  end
</span><span class='line'>  #
</span><span class='line'>  # To determine any of the service JMXTrans depends on is started after JMXTrans service
</span><span class='line'>  #
</span><span class='line'>  only_if {process_require_restart?(&ldquo;jmxtrans&rdquo;,&ldquo;jmxtrans-all.jar&rdquo;, jmx_srvc_cmds)}
</span><span class='line'>end
</span><span class='line'>&hellip;</span></code></pre></td></tr></table></div></figure></p>

<p>As you may have noticed there is a <code>only_if</code> condition calls a library function which takes in a hash of all the services and the string which identifies the service processes as the third paramter. The first two paramters passed are the JMXTrans service name and a string which can uniquely identify a running JMXTrans process.</p>

<p>The following is the code snippet of the library function and the complete code can be found <a href="https://github.com/bloomberg/chef-bach/blob/master/cookbooks/bcpc_jmxtrans/libraries/utils.rb">here</a>.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>def process_require_restart?(process_name, process_cmd, dep_cmds)
</span><span class='line'>  tgt_proces_pid = &lt;code>pgrep -f #{process_cmd}&lt;/code>
</span><span class='line'>  &hellip;
</span><span class='line'>  #
</span><span class='line'>  # Find the start time of the JMXTrans process
</span><span class='line'>  #
</span><span class='line'>  tgt_proces_stime = &lt;code>ps --no-header -o start_time #{tgt_process_pid}&lt;/code>
</span><span class='line'>  &hellip;
</span><span class='line'>  ret = false
</span><span class='line'>  restarted_processes = Array.new
</span><span class='line'>  #
</span><span class='line'>  # Loop through the processess of all the dependent services
</span><span class='line'>  #
</span><span class='line'>  dep_cmds.each do |dep_process, dep_cmd|
</span><span class='line'>    dep_pids = &lt;code>pgrep -f #{dep_cmd}&lt;/code>
</span><span class='line'>    if dep_pids != &ldquo;&rdquo;
</span><span class='line'>      dep_pids_arr = dep_pids.split(&ldquo;\n&rdquo;)
</span><span class='line'>      dep_pids_arr.each do |dep_pid|
</span><span class='line'>        #
</span><span class='line'>        # Find the start time of a dependent process
</span><span class='line'>        #
</span><span class='line'>        dep_process_stime = &lt;code>ps --no-header -o start_time #{dep_pid}&lt;/code>
</span><span class='line'>        #
</span><span class='line'>        # If the dependent process start time is greater than JMXTrans start time
</span><span class='line'>        # set the return value to true
</span><span class='line'>        #
</span><span class='line'>        if DateTime.parse(tgt_proces_stime) &lt; DateTime.parse(dep_process_stime)
</span><span class='line'>          restarted_processes.push(dep_process)
</span><span class='line'>          ret = true
</span><span class='line'>        end
</span><span class='line'>  &hellip;</span></code></pre></td></tr></table></div></figure></p>

<p>The logic behind the library function is to compare the start time of the JMXTrans process against the start time of processes of all the services it is dependent on. If any of the dependent processes start time is later than the start time of JMXTrans process then the JMXTrans service will get restarted.</p>

<p>It would be good to have a Chef primitive that can accomplish what the library function does so that similar situations can use it. Hope this provides a solution option to restart a service dependent on multiple services during a <code>chef-client</code> run.</p>

<p>More notes on this category can be found <a href="http://blog.asquareb.com/blog/categories/chef/">here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dynamically Requesting a Common Service in a Chef Managed Environment]]></title>
    <link href="http://asquareb.github.io/blog/2015/02/21/dynamically-requesting-a-common-service-in-a-chef-managed-environment/"/>
    <updated>2015-02-21T22:39:48-04:00</updated>
    <id>http://asquareb.github.io/blog/2015/02/21/dynamically-requesting-a-common-service-in-a-chef-managed-environment</id>
    <content type="html"><![CDATA[<p>In a cluster environment there can be a common service running on all the nodes in the cluster which may be requested by an application using the cluster. For e.g. in a distributed computing environment logs can be created on each node in the cluster and a common service on each cluster node can be a service which regularly copies log entries into a common location. Copying of logs can be a requirement for some of the applications/services running on the cluster nodes so that users can go to one location to view the log data from all the nodes instead of looking at each node. This can also help with managing the security of the cluster by providing access to this common location instead of providing access to all the nodes in the cluster.</p>

<!-- more -->


<p>But copying of the logs may not be a requirement for some other service or application and the requirement may change in the future. It is better to build a solution so that the changes in the requirements to copy logs can be accommodated dynamically.</p>

<p>To explain the pattern on how we can accomplish the requirement, we will assume <code>Apache Flume</code> as the component which will be installed on all the nodes in the cluster and will be used to copy the log file entries to a common location in HDFS. The following is one solution to satisfy the requirement.</p>

<p>Create a new cookbook or reuse an existing cookbook which will be used on all the nodes in the cluster. Create a node attribute which will store a hash of hashes. For e.g.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>default[&lsquo;bcpc&rsquo;][&lsquo;hadoop&rsquo;][&lsquo;copylog&rsquo;] = {}</span></code></pre></td></tr></table></div></figure></p>

<p>The following is the datastructure which will be used to populate the hash values to be stored in the attributes</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  &lsquo;app_id&rsquo; =>  { &lsquo;logfile&rsquo; => &ldquo;/path/file_name_of_log_file&rdquo;,
</span><span class='line'>                 &lsquo;docopy&rsquo; => true (or false)
</span><span class='line'>                },&hellip;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure></p>

<p>where the <code>app_id</code> is an unique id of an application which requests the service to copy its logs, <code>logfile</code> is the path of the logfile and <code>docopy</code> is a flag to enable and disable the request to copy the log files based on change in need. If an application requests more than one logfile to be copied the <code>appli_id</code> need to be made unique with in the application by adding additonal details like log name or a sequence number.</p>

<p>When an application need to make a request to copy its log file, in the application&rsquo;s recipe, request can be added to the node attribute. For e.g. if logs from the nodes running <code>hbase-region-server</code> need to copy its logs to the common location, code similar to the following can be included in the recipe installing and starting the <code>hbase-region-server</code> service.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>node.default[&lsquo;bcpc&rsquo;][&lsquo;hadoop&rsquo;][&lsquo;copylog&rsquo;][&lsquo;hbase_regionserver_log&rsquo;] = {
</span><span class='line'>    &lsquo;logfile&rsquo; => &ldquo;/var/log/hbase/hbase-regionserver-#{node.hostname}.log&rdquo;,
</span><span class='line'>    &lsquo;docopy&rsquo; => true
</span><span class='line'>}&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;p>node.default[&lsquo;bcpc&rsquo;][&lsquo;hadoop&rsquo;][&lsquo;copylog&rsquo;][&lsquo;hbase_regionserver_out&rsquo;] = {
</span><span class='line'>    &lsquo;logfile&rsquo; => &ldquo;/var/log/hbase/hbase-regionserver-#{node.hostname}.out&rdquo;,
</span><span class='line'>    &lsquo;docopy&rsquo; => true
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure></p>

<p>Note here how an unique identifier is used as the <code>app_id</code> for the two log files from <code>hbase_regionserver</code> to be copied to the common location in HDFS.</p>

<p>For someone not familiar with <code>Flume</code>, flume agents can be used to move data and they need a config file which defines things like the source, sink, the type of sink,the target location etc. Since <code>Flume</code> need to be installed in all nodes in the cluster to be a common service, a recipe need to be created to install the software. But when it comes to start <code>Flume agents</code>, the recipe need to loop through the node attribute to create required Flume configuration files for each logfile copy requests made by the applications running on the node.</p>

<p>For e.g if the node is running only <code>hbase_regionserver</code> there will be two copy requests in the attribute for which the recipe need to create Flume configuration files and start the corresponding <code>Flume agents</code>. If there are other applications/services running on the node for e.g. <code>HDFS Datanode</code> and if the recipes make copy requests then the number of flume configs and <code>flume agents</code> running on the node will be more. The following is the code snippet on how the <code>Flume</code> recipe can accomplish this</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&hellip;
</span><span class='line'>node[&lsquo;bcpc&rsquo;][&lsquo;hadoop&rsquo;][&lsquo;copylog&rsquo;].each do |id,f|
</span><span class='line'>   if f[&lsquo;docopy&rsquo;]
</span><span class='line'>     template &ldquo;/etc/flume/conf/flume-#{id}.conf&rdquo; do
</span><span class='line'>       source &ldquo;flume_flume-conf.erb”
</span><span class='line'>       action :create &hellip;
</span><span class='line'>       variables(:agent_name => &rdquo;#{id}&ldquo;,
</span><span class='line'>                 :log_location => &rdquo;#{f[&lsquo;logfile&rsquo;]}&ldquo; )
</span><span class='line'>       notifies :restart,"service[flume-agent-multi-#{id}]&rdquo;,:delayed
</span><span class='line'>     end
</span><span class='line'>     service &ldquo;flume-agent-multi-#{id}&rdquo; do
</span><span class='line'>       supports :status => true, :restart => true, :reload => false
</span><span class='line'>       service_name &ldquo;flume-agent-multi&rdquo;
</span><span class='line'>       action :start
</span><span class='line'>       start_command &ldquo;service flume-agent-multi start #{id}&rdquo;
</span><span class='line'>       restart_command &ldquo;service flume-agent-multi restart #{id}&rdquo;
</span><span class='line'>       status_command &ldquo;service flume-agent-multi status #{id}&rdquo;
</span><span class='line'>     end
</span><span class='line'>&hellip;</span></code></pre></td></tr></table></div></figure></p>

<p>A complete <code>Flume</code> recipe which includes this feature is available <a href="https://github.com/bloomberg/chef-bach/blob/master/cookbooks/bcpc-hadoop/recipes/copylog.rb">here</a>.</p>

<p>By default the init.d script for Flume starts one <code>Flume agent</code>. But BIGTOP jira <a href="https://issues.apache.org/jira/browse/BIGTOP-1581">BIGTOP-1581</a> provides an option to start/stop/restart flume agents by passing agent names as in the <code>service</code> resource in the previous code snippet. The name passed need to have a corresponding Flume config file under the configuration folder. Since <code>Flume</code> recipe need to know the copy request from all the applications running on the node, it should be the last recipe to be run on the node. This can be accomplished by creating a role to include the <code>Flume</code> recipe and add it to the end of chef-client runlist of all the nodes.</p>

<p>Hope this provides a solution option in a similar situation where applications can dynamically request for a common service in an environment. Also note that the data structure can be expanded so that applications can make richer requests for e.g. in this case request to change the location of the common location where logs are copied into etc.</p>

<p>More notes on this category can be found <a href="http://blog.asquareb.com/blog/categories/chef/">here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Build Your Hadoop Cluster Unattended (Almost!!)]]></title>
    <link href="http://asquareb.github.io/blog/2014/12/27/build-your-hadoop-cluster-unattended-almostls/"/>
    <updated>2014-12-27T21:13:36-05:00</updated>
    <id>http://asquareb.github.io/blog/2014/12/27/build-your-hadoop-cluster-unattended-almostls</id>
    <content type="html"><![CDATA[<p>If you are a developer who would like to have a Hadoop cluster or a dev lead who would like everyone in your team a cluster of their own without going through the hassle of creating machines, networking them, install the required software components, <a href="https://github.com/bloomberg/chef-bach">chef-bach</a> is an option you want to try.</p>

<!-- more -->


<p>Chef-Bach is a set of <a href="https://www.chef.io/">Chef</a> cookbooks which can be used bring up a Hadoop cluster. It is open source software and that means it can be customized to your needs. By default, a &ldquo;Test-Laptop&rdquo; configuration will bring up a three node Hadoop cluster based on <a href="http://hortonworks.com/products/releases/hdp-2-0-ga/">HDP 2.0</a> on a laptop or machine with enough resources like 16 GB RAM and quad core processor. Behind the scenes, chef-bach will create VM machines using VirtualBox, configures the network, PXE boots the cluster nodes, installs OS and deploys the Hadoop components with out any user intervention (almost).</p>

<p>The total time to create a &ldquo;Test-Laptop&rdquo; cluster is around 3 hours and that means at anytime the cluster can be destroyed and rebuilt without much loss in time or productivity of developers. If this is something of interest to you, refer to the instructions to perform the cluster creation process <a href="https://gist.github.com/cbaenziger/816e7c42913433f5743f">here</a>. Also users will be able to create a cluster with <a href="https://gist.github.com/bijugs/27f44d51b69402eb90ab">more than 3 nodes</a> or <a href="https://gist.github.com/bijugs/27f44d51b69402eb90ab">add new nodes</a> to the cluster after the cluster has been created.</p>

<p>Even though test cluster creation is mentioned as the primary use case so far, nothing prevents someone to use chef-bach to create production clusters and for that matter it is currently being used in production environment. Some of the notable features which makes it production capable include</p>

<ul>
<li>deployment of key components like mysql server, graphite, zabbix etc in HA mode</li>
<li>monitoring and triggering using Zabbix and Graphite</li>
<li>all JMX and server statistics made available on Graphite so that graphs using various data points can be created for better insight</li>
<li>rolling restart of various Hadoop components to prevent unavailability during configuration changes</li>
<li>being able to run chef as daemon process at regular intervals so that all the nodes are kept updated</li>
<li>copy of logs from various nodes into a centralized location (HDFS) so that users can access them for debugging</li>
<li>option to create a <a href="https://kafka.apache.org/">Kafka</a> cluster</li>
</ul>


<p>As a open source project you can also get involved and influence the future direction of this project.</p>

<p>More notes on this category can be found <a href="http://blog.asquareb.com/blog/categories/chef/">here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Adding Users to Graphite]]></title>
    <link href="http://asquareb.github.io/blog/2014/11/19/adding-users-to-graphite/"/>
    <updated>2014-11-19T14:42:56-05:00</updated>
    <id>http://asquareb.github.io/blog/2014/11/19/adding-users-to-graphite</id>
    <content type="html"><![CDATA[<p>Once you start populating data to Graphite database, users can see data on Graphite UI and create custom graphs to see the data in realtime. When graphs are created users want to save the graphs for future use and probably want to create a dashboard with all the graphs created. One simple (but non user friendly) way to accomplish this is to save the URLs of the graphs created and users can use it to bring up the graphs when they need them.</p>

<!-- more -->


<p>Another option is to use the graph save option in Graphite web app UI which also provides an option to create and save dashboards. Both these options require logging onto web app which requires an user-id/password to log on to the web app. Here is the way to go about creating one.</p>

<ul>
<li>Logon to the server running Graphite web app</li>
<li><code>cd</code> to <code>/opt/graphite/webapp/graphite/</code> (or the install directory)</li>
<li>Execute the python script <code>manage.py</code> with the option <code>createsuperuser</code></li>
</ul>


<pre><code>  python manage.py createsuperuser
  Username (Leave blank to use 'root'): test
  E-mail address: test@happyday.com
  Password:
  Password (again):
  Superuser created successfully.
</code></pre>

<ul>
<li><code>admin</code> user is defined during installation and if you don&rsquo;t know the password (for admin or any user) run</li>
</ul>


<pre><code>  python manage.py changepassword
</code></pre>

<ul>
<li>Once you have the user-id/password set the user can log on to the web app and create graphs/dahsboards and save them for future use.</li>
</ul>

]]></content>
  </entry>
  
</feed>
